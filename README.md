# ðŸ§  RAG Chatbot API (FastAPI + Docker)

A **Retrieval-Augmented Generation (RAG) Chatbot API** built with:
- **FastAPI** for serving endpoints
- **LangChain** for pipeline orchestration
- **HuggingFace Transformers** for free embeddings + LLMs
- **FAISS** for vector database
- **Docker** for containerization

---

## ðŸš€ Features
- `/health` â†’ Health check endpoint
- `/ask` â†’ Ask any question, chatbot retrieves context from PDF + generates an answer
- Uses HuggingFace `flan-t5-base` by default (no paid API needed!)
- Fully containerized with Docker

---
![Swagger UI](docs/swagger.png)


## ðŸ“‚ Project Structure

Project_2/
â”œâ”€â”€ app/                     # FastAPI application code
â”‚   â”œâ”€â”€ __init__.py          # Makes app a package
â”‚   â”œâ”€â”€ main.py              # API endpoints (health, ask)
â”‚   â””â”€â”€ rag_pipeline.py      # RAG pipeline (embeddings, vector store, QA chain)
â”œâ”€â”€ artifacts/               # Stores FAISS vector database
â”‚   â”œâ”€â”€ index.faiss
â”‚   â””â”€â”€ index.pkl
â”œâ”€â”€ data/                    # Input documents (PDFs, etc.)
â”‚   â””â”€â”€ Attention.pdf
â”œâ”€â”€ docs/                    # Documentation and assets
â”‚   â””â”€â”€ swagger.png          # Swagger UI screenshot
â”œâ”€â”€ .env                     # Environment variables (API keys, configs)
â”œâ”€â”€ Dockerfile               # Docker configuration
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ run_me_once.py           # Script to build vector store
â””â”€â”€ README.md                # Project documentation

